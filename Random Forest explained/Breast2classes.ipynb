{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9a176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "# from decision_tree_functions import decision_tree_algorithm1, decision_tree_predictions\n",
    "from helper_functions import train_test_split, calculate_accuracy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from helper_functions import determine_type_of_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc17ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrapping(train_df, n_bootstrap):\n",
    "    bootstrap_indices = np.random.randint(low=0, high=len(train_df), size=n_bootstrap)\n",
    "    df_bootstrapped = train_df.iloc[bootstrap_indices]\n",
    "    \n",
    "    return df_bootstrapped\n",
    "\n",
    "def random_forest_algorithm(train_df, n_trees, n_bootstrap, n_features, dt_max_depth):\n",
    "    forest = []\n",
    "    for i in range(n_trees):\n",
    "        df_bootstrapped = bootstrapping(train_df, n_bootstrap)\n",
    "        tree = decision_tree_algorithm1(df_bootstrapped,0,2, max_depth=dt_max_depth, xinchao=n_features)\n",
    "        forest.append(tree)\n",
    "    \n",
    "    return forest\n",
    "\n",
    "def random_forest_predictions(test_df, forest):\n",
    "    df_predictions = {}\n",
    "    for i in range(len(forest)):\n",
    "        column_name = \"tree_{}\".format(i)\n",
    "        predictions = decision_tree_predictions(test_df, tree=forest[i])\n",
    "        df_predictions[column_name] = predictions\n",
    "\n",
    "    df_predictions = pd.DataFrame(df_predictions)\n",
    "    random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
    "    \n",
    "    return random_forest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5e8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decision Tree helper functions\n",
    "# (see \"decision tree algorithm flow chart.png\")\n",
    "\n",
    "# 1.1 Data pure?\n",
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# 1.2 Classify\n",
    "def classify_data(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "\n",
    "    return classification\n",
    "\n",
    "\n",
    "# 1.3 Potential splits?\n",
    "def get_potential_splits(data, random_subspace):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    column_indices = list(range(n_columns - 1))  # excluding the last column which is the label\n",
    "\n",
    "    if random_subspace and random_subspace <= len(column_indices):\n",
    "        column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "\n",
    "    for column_index in column_indices:\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        potential_splits[column_index] = unique_values\n",
    "\n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "# 1.4 Lowest Overall Entropy?\n",
    "def calculate_entropy(data):\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)\n",
    "                       + p_data_above * calculate_entropy(data_above))\n",
    "\n",
    "    return overall_entropy\n",
    "\n",
    "\n",
    "def determine_best_split(data, potential_splits):\n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "\n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "# 1.5 Split data\n",
    "def split_data(data, split_column, split_value):\n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values > split_value]\n",
    "\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "\n",
    "    return data_below, data_above\n",
    "\n",
    "\n",
    "# 2. Decision Tree Algorithm\n",
    "def decision_tree_algorithm1(df, counter=0, min_samples=2, max_depth=5, xinchao=None):\n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "\n",
    "        # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "\n",
    "        return classification\n",
    "\n",
    "\n",
    "    # recursive part\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "        # helper functions\n",
    "        potential_splits = get_potential_splits(data, xinchao)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "\n",
    "        # check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "\n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "\n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "\n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "\n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm1(data_below, counter, min_samples, max_depth, xinchao)\n",
    "        no_answer = decision_tree_algorithm1(data_above, counter, min_samples, max_depth, xinchao)\n",
    "\n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "\n",
    "        return sub_tree\n",
    "\n",
    "\n",
    "# 3. Make predictions\n",
    "# 3.1 One example\n",
    "def predict_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "\n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)\n",
    "\n",
    "\n",
    "# 3.2 All examples of the test data\n",
    "def decision_tree_predictions(test_df, tree):\n",
    "    predictions = test_df.apply(predict_example, args=(tree,), axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f95be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train-Test-Split\n",
    "def train_test_split(df, test_size):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# 2. Distinguish categorical and continuous features\n",
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "\n",
    "    return feature_types\n",
    "\n",
    "\n",
    "# 3. Accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    predictions_correct = predictions == labels\n",
    "    accuracy = predictions_correct.mean()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb3729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Breast2classes.csv\")\n",
    "df.columns.values[0] = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28677855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11171331",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = random_forest_algorithm(train_df, n_trees=40, n_bootstrap=800, n_features=2, dt_max_depth=4)\n",
    "predictions = random_forest_predictions(test_df, forest)\n",
    "accuracy = calculate_accuracy(predictions, test_df.label)\n",
    "\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785fc18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
